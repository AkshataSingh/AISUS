{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "123d8bb2",
   "metadata": {},
   "source": [
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f7db3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e7ca87",
   "metadata": {},
   "source": [
    "# 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f56b0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations specific to EfficientNetV2\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),  # Specific size for EfficientNetV2\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dir = 'output_dataset/train'\n",
    "val_dir = 'output_dataset/val'\n",
    "test_dir = 'output_dataset/test'\n",
    "\n",
    "train_dataset = ImageFolder(root=train_dir, transform=transform)\n",
    "val_dataset = ImageFolder(root=val_dir, transform=transform)\n",
    "test_dataset = ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Dataset sizes\n",
    "dataset_sizes = {\n",
    "    'train': len(train_dataset),\n",
    "    'val': len(val_dataset)\n",
    "}\n",
    "\n",
    "# Data loaders dictionary\n",
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bd96c5",
   "metadata": {},
   "source": [
    "# 3. Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3655ed6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shash\\OneDrive\\Desktop\\ai-and-sus\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\shash\\OneDrive\\Desktop\\ai-and-sus\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_S_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth\" to C:\\Users\\shash/.cache\\torch\\hub\\checkpoints\\efficientnet_v2_s-dd5fe13b.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82.7M/82.7M [00:17<00:00, 4.83MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained EfficientNetV2 model\n",
    "model = models.efficientnet_v2_s(pretrained=True)\n",
    "\n",
    "# Modify the final fully connected layer for your specific task\n",
    "num_classes = len(train_dataset.classes)\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd447db2",
   "metadata": {},
   "source": [
    "# 4. Fine-tune the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1495a9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1\n",
      "train Loss: 1.0815 Acc: 56.1905\n",
      "val Loss: 1.1982 Acc: 57.7778\n",
      "\n",
      "Training complete in 3m 22s\n",
      "Best val Acc: 57.7778\n"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Learning rate scheduler\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # Initialize history dictionary to store metrics\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch + 1}/{num_epochs}')\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc * 100:.4f}')\n",
    "\n",
    "            # Store in history\n",
    "            history[f'{phase}_loss'].append(epoch_loss)\n",
    "            history[f'{phase}_acc'].append(epoch_acc.item())  # Convert tensor to float\n",
    "\n",
    "            # Save best model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'\\nTraining complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc * 100:.4f}')\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history\n",
    "\n",
    "# Train the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model, history = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa11be7",
   "metadata": {},
   "source": [
    "# 5. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1255f8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'efficientnetv2_baseline.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b9bcb1",
   "metadata": {},
   "source": [
    "# 6. Prune the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f2e26e",
   "metadata": {},
   "source": [
    "### 6.1 Define baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6901b661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load pre-trained EfficientNetV2 model\n",
    "model = models.efficientnet_v2_s(pretrained=True)\n",
    "\n",
    "num_classes = 4 \n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "\n",
    "# Load your own saved trained weights\n",
    "model.load_state_dict(torch.load('efficientnetv2_baseline.pth'))\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb173b7",
   "metadata": {},
   "source": [
    "### 6.2 Prunning configuration with 30% Weights pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc35b57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "def prune_and_remove(model, amount=0.3):\n",
    "    \"\"\"\n",
    "    Prunes 30% of weights in all Conv2d and Linear layers, then makes it permanent.\n",
    "    \"\"\"\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            # Apply unstructured L1 pruning\n",
    "            prune.l1_unstructured(module, name='weight', amount=amount)\n",
    "            # Remove the pruning mask and make it permanent\n",
    "            prune.remove(module, 'weight')\n",
    "    return model\n",
    "\n",
    "pruned_model = prune_and_remove(model, amount=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cc4170",
   "metadata": {},
   "source": [
    "### 6.3 Train pruned model and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984ba22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1\n",
      "train Loss: 0.7339 Acc: 71.9048\n",
      "val Loss: 0.9691 Acc: 66.6667\n",
      "\n",
      "Training complete in 3m 19s\n",
      "Best val Acc: 66.6667\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(pruned_model.parameters(), lr=0.0001)\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# Train again\n",
    "pruned_model, pruned_history = train_model(pruned_model, criterion, optimizer, exp_lr_scheduler, num_epochs=10)\n",
    "\n",
    "# Save pruned model\n",
    "torch.save(pruned_model.state_dict(), 'efficientnetv2_pruned.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc6d418",
   "metadata": {},
   "source": [
    "# 7. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdb3ac27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Accuracy: 53.84615384615385%\n",
      "Pruned Model Accuracy: 70.32967032967034%\n"
     ]
    }
   ],
   "source": [
    "# Define evaluation function\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Evaluate baseline model\n",
    "model.load_state_dict(torch.load('efficientnetv2_baseline.pth'))\n",
    "baseline_accuracy = evaluate_model(model, test_loader)\n",
    "print(f'Baseline Model Accuracy: {baseline_accuracy}%')\n",
    "\n",
    "# Evaluate pruned model\n",
    "model.load_state_dict(torch.load('efficientnetv2_pruned.pth'))\n",
    "pruned_accuracy = evaluate_model(model, test_loader)\n",
    "print(f'Pruned Model Accuracy: {pruned_accuracy}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
